Image Classifiers are AI. They identify and classify objects.
However, LLMs are not.

LLMs play only with languages.
They do not deal with epistemology and connecting language to ideas.

So they can be used to convert written ideas to more easily digestible summaries.
However, they can't be used to infer new information.

# Support
While Stallman calls them "bullshit generator", and I think that's true, it's still good to find if you get something useful out of pure bullshit.

(I went in two division of thought from this; I really have to figure out how to properly represent writings in this thinking pattern XD:)
## Division 1 ()
4] It's easier for people to say that science was built on proper methods in retrospect.
3] But in reality, many inventions were based on people simply messing around with things.

1] Poetry and beautiful works of Art have often been generated through accidents.
2] Meaning and Beauty don't always overlap.
## Division 2
5] For example, similar principles have been used to make AI that navigates obstacles or performs some other action, purely based on memory, without a direct knowledge of what that action implies.

6] There's also the question of ..Humans
# Good Alternate Approaches
- Use them like Grammarly does (validate grammar)
- Use them to resummarize information