I mean this to include hacking software, prompt injections (on AI Models), doublespeak (linguistics), and war.

## Prompt Injections
- People have used doublespeak to break LLM models to access hidden prompts.