**Links:**
[[Machine Learning Frameworks]]

# Types of Neural Networks
- Feed Forward Neural Network (FfNN)
	- Perceptron
	- Multi Layer Perceptron (MLP)
	- Autoencoders
	- Radial Basis Function Neural Networks (RBF)
- Convolutional Neural Network (CNN)
- Recurrent Neural Network (RNN)
	- Long Short Term Memory (LSTM)
	- Gated Recurrent Unit (GRU)
	- Attention based
- Generative Adversarial Network (GAN)
- Transformers
- Sequence to Sequence Neural Networks (consists of two RNNs)
- Modular Neural Networks

1. FFNNs
	1. Perceptron
	2. Multi-layer perceptron (MLP) 
	3. Radial basis function (RBF) network 
	4. Feedforward neural networks with Rectified Linear Units (ReLU) activation
	5. Reservoir Computing (RC)
2. CNNs
3. RNNs 
	1. LSTM 
	2. GRU
	3. Attention based recurrent unit (ARU) 
	4. Echo state networks (ESN)
4. Transformers
5. Modular Neural Networks
6. Autoencoders
	1. Variational Autoencoders (VAE)
	2. Denoising Autoencoders (DAE)
	3. Dual Avatar Autoencoders (DAAE)
7. Sequence to Sequence Neural Encoders (Seq2seq)
8. Generative Adversarial Networks (GAN)
9. Denoising Adversarial Networks (DAN)
10. Energy-Based Architectures
11. Variational Bayesian Inference

# Terms
- Frameworks
- Networks - Models and Networks are often used interchangeably. But mainly the difference is that algorithms are implemented on networks to create models.
- [[AI Algorithms]]
- Models - Products of AI Training, by running a machine learning algorithm on training data
- Inference - Inference is where deep learning capabilities learned during training are put to work